# De-Sign-Pher: Indian-Sign-language Detection
The goal of this project was to build a neural network able to classify which number of the Indian Sign Language (ISL) dataset is being signed, given an image of a signing hand. This project is a first step towards building a possible Indian sign language translator, which can take communication in sign language and translate them into written language. Such a translator would greatly lower the barrier for many deaf and mute individuals to be able to better communicate with others in day-to-day interactions. This project uses the Convolution Neural Network and Artificial Neural Network to extract useful features of the hand, while the sign language is being presented in front of the camera. This research includes a dataset created on our own by recreating the Indian Sign Language. The technique of Gaussian Blur is implemented and this paper ends up with a total accuracy of 96%. We plan to incorporate all alphabets and numbers into this project and that it should be able to detect the entire sentence. Similarly, we hope to work on generating more training data and images for improvement in the accuracy percentage under various conditions.
